<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" >
<topic xml:lang="en-us" id="topic2502">
  <title>HPE Helion 2.0 Development Platform: Release Notes</title>
  <body>
    <p>The following release notes are for the HPE Helion Development Platform 2.0 released in
      November, 2015. We hope you enjoy the release!</p>
    
    <section><title>In This Release:</title>
    <p>HPE Helion Development Platform is comprised of the following services:</p>
      <ul>
        <li>Development Platform Installer version 2.0.0.2</li>
        <li>Application Lifecycle Service version 2.0.0.548 </li>
        <li>Database Service version 2.0.0.38 </li>
        <li>Messaging Broker Service version 1.0.0.165 </li>
        <li>Helion Code Engine version 1.0.0.42 </li>
        <li>DNS as a Service version 2.0.0.190</li>
        
      </ul>
    
    
    </section>
    <section>
      <title>What's New</title>
      <p>This release contains key functionality to make building and deploying cloud native apps
        easier and faster for our customers.</p>
      <ul>
        <li>Enterprises can deploy microservices packaged as Docker containers into a managed Cloud
          Foundry-based Platform-as-a-Service (PaaS). </li>
        <li>This  release includes the new HPE Helion Code Engine - a continuous
          integration/continuous delivery (CI/CD) toolchain for automating the build/test/deploy
          workflow to help you modernize their development experience.</li>
        <li>Further integrating IaaS + PaaS, this release provides support for clustered MySQL,
          MongoDB, and Redis. </li>
        <li>It also includes a technical preview of Vertica in our Database as a Service offering. </li>
        <li>The Messaging Broker Service supports RabbitMQ cluster provisioning.</li>
        <li>Monitoring alerts available through Monasca for the Messaging Broker service and the
          Database Service.</li>
        <li>Improved documentation with targeted search and new user feedback link.</li>
      </ul>
    </section>
    
    <section>
      <title>2.0 General Notes</title>
      <dl>
        <dlentry>
          <dt>Enable Monasca Monitoring for the Database Service</dt>
          <dd> The following instructions will enable the Monasca agent on the DBaaS control plane.
              <note>These instructions assume that you have permission to SSH into the control
              plane.</note><ol>
              <li> Secure copy the following packages onto <b>each</b> control plane
                instance:<codeblock>Six-1.9.0
Python-keystoneclient-0.10.1
Oslo.i18n-1.5.0
Pbr-0.11.0
Oslo.utils-1.4.0
Oslo.serialization-1.4.0
Stevedore-1.3.0
Oslo.config-1.3.0</codeblock></li>
              <li>Use <codeph>pip install</codeph> to install the packages <b>in the order
                  listed</b>.</li>
              <li> Run <codeph>bash /etc/monasca/start-monasca</codeph> to set up the Monasca agent
                on that machine.</li>
            </ol></dd>
        </dlentry>
        <dlentry>
          <dt>Manual Creation of the Database Endpoint</dt>
          <dd> If the installer fails to create the database endpoint at the end of the
            installation, run the following commands to manually create one. You will need to supply
            the IP address of the
            VIP.<codeblock>$ openstack service create --name database database
$ openstack endpoint create database admin 'http://<i>&lt;public-VIP-IP-address></i>:8779/v1.0/$(tenant_id)s'
$ openstack endpoint create database internal 'http://<i>&lt;public-VIP-IP-address></i>:8779/v1.0/$(tenant_id)s'
$ openstack endpoint create database public 'http://<i>&lt;public-VIP-IP-address></i>:8779/v1.0/$(tenant_id)s'</codeblock></dd>
        </dlentry><dlentry>
          <dt>Multiple Syntax Errors in Python pip Install Output</dt>
          <dd>Installing a Python package also installs any required dependencies. This may generate
            several syntax warnings inline as the install occurs. This is expected behavior, and
            unless the output of the pip install reflects a fatal error, the install is still
            considered "clean".</dd>
        </dlentry>
      </dl>
    </section>
    <section>
      <title>Known Issues</title>
      <dl><dlentry>
        <dt>Alarms appear in "No Service Defined" Panel</dt>
        <dd>If the Message Broker sends alarms for MySQL or Zookeeper, they appear in the "No Service Defined" panel of the Opsconsole, not the Messaging as a Service panel. This is a known issue.</dd>
      </dlentry>
        <dlentry>
        <dt>Creating an ALS cluster results in error: 413 Request Entity Too Large</dt>
        <dd>When using the <codeph>cf-mgmt</codeph> tool, cluster creation fails because the payload
            sent to OpenStack to boot a new instance was too large. This is caused by including
            certificates in the payload. To fix this, skip SSL validation or use Horizon to create
            the cluster instead.<ol>
              <li>Launch the <codeph>cf-mgmt</codeph> tool.</li>
              <li>Add the <codeph>--skip-ssl-validation</codeph> parameter prior to the cluster
                creation command.
                <codeblock>cf-mgmt --skip-ssl-validation create-cluster <i>[command options]</i> <i>[arguments...]</i></codeblock></li>
            </ol></dd>
      </dlentry>
        <dlentry>
          <dt>UTM or Gateway Firewalls</dt>
          <dd>UTM (Unified Threat Management) or Gateway firewalls may interfere with upgrades,
            patches, or normal application staging if they are configured to inspect all HTTP(S)
            traffic between ALS nodes and upstream package repositories. <xref
              href="helion/admin/cluster/cluster_index.dita#topic18326/utm">See the full
              documentation</xref> for a detailed explanation and suggested solutions.</dd>
        </dlentry>
        <dlentry>
          <dt>Harbor (Port Service) Node Configuration </dt>
          <dd>The optional <xref href="helion/admin/cluster/harbor.dita">Harbor TCP/UDP port
              service</xref> must be set up on a node with a public network interface if you wish to
            enable port forwarding for user applications. The security group or firewall settings
            for this node should make the configured port range accessible publicly.</dd>
        </dlentry>
        <dlentry>
          <dt>Create Clusters with Horizon or <i>cf-mgmt </i>Tool Only</dt>
          <dd>Use only the Horizon UI or the <i>cf-mgmt</i> command line tool to create ALS
            clusters. Using <codeph>kato node attach</codeph> or other methods are unsupported and
            will not function properly.</dd>
        </dlentry>
        <dlentry>
          <dt>Multiple Admin Password Prompts During Patch</dt>
          <dd>When patching, the admin will be prompted for the password at least once and usually
            multiple times. This is a known issue.</dd>
        </dlentry>
        <dlentry>
          <dt>Disk Allocation Min/Max for <codeph>helion push --disk</codeph></dt>
          <dd>The application disk reservation setting has a minimum value of 512 MB and a maximum
            of 2 GB. This is a per-instance limit.</dd>
        </dlentry>
        <dlentry>
          <dt>Cluster Creation Fails, Log File Contains EOF Error</dt>
          <dd>When creating a new ALS cluster, the creation fails. The
              <codeph>/tmp/als_installer.txt</codeph> logfile, located on the constructor VM,
            contains EOF errors. To fix this error, open the configuration management tool and enter
              <codeph>cf-mgmt --disable-connection-reuse true</codeph>. This setting ensures a new
            HTTP connection every time a request is made.</dd>
        </dlentry>
        <dlentry>
          <dt>Cluster Creation Fails with "Disambiguate Network" Error</dt>
          <dd>Creating a cluster fails and the following error message is received:
            <codeblock>validating 'Network' failed, reason: More than one external network, disambiguate with external-network-name or external-network-id</codeblock>
            If an environment has multiple external networks, cluster creation may require a
            specific identifier to determine which to use. <ol id="ol_bcl_b31_vt">
              <li>Determine which network you wish to use. Either use Horizon to view the entire
                list or use a command line argument such as
                <codeblock>neutron net-list</codeblock></li>
              <li>Then pass that external network's name or id using the configuration management
                tool as follows:
                <codeblock>cf-mgmt cc --external​-network-n​ame &lt;mynetworkName></codeblock><codeblock>cf-mgmt cc --external​-network-id &lt;mynetworkID></codeblock></li>
            </ol></dd>
        </dlentry>
        <dlentry>
          <dt>DNS 2.0</dt>
          <dd>
            <b>New Features</b>
            <ul>
              <li>New API V2 <ul>
                  <li>Adds Zones that replaces Domains from V1.</li>
                  <li>Adds RecordSets that replaces Records from V1. </li>
                </ul></li>
              <li>Scalability and Resilience improvements <ul>
                  <li>New service PoolManager that handles coordination / resiliency.</li>
                  <li>New service MiniDNS.</li>
                </ul></li>
              <li>Support for wildcard records.</li>
              <li>Support for Secondary Zones.</li>
            </ul>
            <b>Known Issues</b>
            <ul>
              <li>Selecting a flavor larger than m1.medium for the Deployer or Control Plane nodes
                fails due to a failure to re-size LVM. The recommended flavors for the Deployer and
                Control Plane nodes are m1.small or m1.medium.</li>
            </ul>
            <b>Not included in the release</b>
            <ul>
              <li>Backend support for BIND9 / DynECT / Akamai is not included in this release.</li>
              <li>Support for Ceilometer is not included in this release.</li>
              <li>There is currently no backup and restore functionality.</li>
            </ul>
            <b>Bugfixes</b>
            <ul>
              <li>API TTL input validation.</li>
              <li>Improve error message on API actions.</li>
              <li>Launchpad 1471161 <ul>
                  <li>CVE-2015-5695 Quotas were being bypassed.</li>
                  <li>CVE-2015-5694 does not enforce the DNS protocol limit concerning record set
                    sizes.</li>
                </ul></li>
              <li>Launchpad 1471158: Incorrect regular expressions used for schema validation.</li>
              <li>Launchpad 1497031: Authenticated Denial of Service in Blacklists.</li>
            </ul></dd>
        </dlentry>
      </dl>
    </section>    <section><title>Database Service</title>
      
      <dl>
        <dlentry>
          <dt>No option to reset password on Vertica Preview instance on Horizon</dt>
          <dd>Vertica clusters can be accessed via credentials obtained by enabling root, either through Horizon or the Trove CLI. Single node 
            Vertica instances must have root enabled through the Trove CLI, as this action is not available in Horizon. </dd>
          <dd>Example:
            <codeblock>trove root-enable &lt;instance&gt;</codeblock></dd>
        </dlentry>
        <dlentry><dt>Searching for log entries returns API KEY ERROR: Missing</dt>
          <dd>The current Vertica Management Console release has a known issue where attempting to search
            for Vertica log entries may result in an API key being requested. As a workaround, it is
            suggested to access Vertica event data directly through the database's ACTIVE_EVENTS,
            QUERY_EVENTS and QUERY_REQUESTS tables, as described in <xref
              href="devplatform.database-vertica.dita#topic_q1p_nnp_tt">Managing a Vertica Preview Cluster from the Management Console</xref>.</dd>
        </dlentry>
        <dlentry><dt>"Stack trove in status ROLLBACK_COMPLETE" message when DBaaS installation fails</dt>
          <dd>The installation process may display a <codeph>ROLLBACK_COMPLETE</codeph> message when installation fails. This may look like the following:  <codeblock>.devplatform)stack@redwood:~$ openstack --os-cloud mycloud hdpi database install --path dbaas-qcow2_2.0.0.31.csu
dbaas-qcow2_2.0.0.31.csu is already downloaded
dbaas-qcow2_2.0.0.31.csu is already (installed)
Disabling SSL Features for databaseervice
Launching stack...
Stack trove creating
Stack trove in status ROLLBACK_COMPLETE
UI installed for database
Create service endpoint for service database
Completed installing database
(.devplatform)stack@redwood:~$</codeblock></dd></dlentry>
        <dlentry><dt>“mysql cluster 5.5” listed as option in Launch Instance dialog</dt>
          <dd>When <b>Launch Instance</b> is selected in the <b>Project->Database->Instances</b> panel in Horizon, a <b>Datastore</b> option of <b>mysql-cluster</b> version <b>5.5</b> is displayed. Selecting this option
            creates a standard <b>mysql</b> cluster.</dd></dlentry>
      </dl></section>
  </body>
</topic>
