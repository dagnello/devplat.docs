<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_fld_zzy_lt">
  <title>HPE Helion <tm tmtype="reg">OpenStack</tm> 2.0: Removing a Compute Node</title>
  <body>
    <!--Needs Work-->
    <section id="removeNodes"> The process for removing a compute node requires that you run these
      steps. Note that to run any playbooks whatsoever for cloud maintenance, you will always run
      from the lifecycle manager.<ol>
        <li>If availability zones are configured, remove the affected node from its availability
          zone.</li>
        <li>Disable provisioning to prevent new instances from being created on this node. </li>
        <li>If possible migrate any instances on the node to other nodes. </li>
        <li>Shut down the node or stop the nova-compute service. </li>
        <li>Delete the compute node from nova </li>
        <li>Amend servers.yml in the cloud configuration to remove entry for this node, commit the
          change and re run the config processor </li>
        <li>Remove the node from cobbler</li>

      </ol>
    </section>

    <section id="removeAZ"><title>Remove Hosts from Host Aggregates</title> When removing a compute
      node, if availability zones have been configured, either manually or using the Nova playbook
        <b>nova-cloud-configure.yml</b>, or you have manually configured any host aggregates, then
      before executing the <codeph>service-delete</codeph> command you need to remove the host(s)
      being deleted from any host aggregates. For example: <ol>
        <li>Disable the
          service<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-disable --reason="HNOV-240 - removed" padawan-ccp-comp0002-mgmt nova-compute</codeblock><codeblock>+---------------------------+--------------+----------+--------------------+
| Host                      | Binary       | Status   | Disabled Reason    |
+---------------------------+--------------+----------+--------------------+
| padawan-ccp-comp0002-mgmt | nova-compute | disabled | HNOV-240 - removed |
+---------------------------+--------------+----------+--------------------+</codeblock></li>
        <li>Get nova service
          list<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-list</codeblock><codeblock>+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                      | Zone     | Status   | State | Updated_at                 | Disabled Reason    |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+
| 1  | nova-conductor   | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:12.000000 | -                  |
| 4  | nova-scheduler   | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 7  | nova-conductor   | padawan-ccp-c1-m3-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:14.000000 | -                  |
| 10 | nova-conductor   | padawan-ccp-c1-m2-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:12.000000 | -                  |
| 13 | nova-scheduler   | padawan-ccp-c1-m3-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 16 | nova-consoleauth | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:14.000000 | -                  |
| 19 | nova-scheduler   | padawan-ccp-c1-m2-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 22 | nova-compute     | padawan-ccp-comp0002-mgmt | AZ2      | disabled | up    | 2015-10-12T08:46:12.000000 | HNOV-240 - removed |
| 25 | nova-compute     | padawan-ccp-comp0001-mgmt | AZ1      | enabled  | up    | 2015-10-12T08:46:11.000000 | -                  |
| 28 | nova-compute     | padawan-ccp-comp0003-mgmt | AZ3      | enabled  | up    | 2015-10-12T08:46:11.000000 | -                  |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock></li>
        <li>Get availability
          zones<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-list</codeblock><codeblock>+----+------+-------------------+
| Id | Name | Availability Zone |
+----+------+-------------------+
| 1  | AZ1  | AZ1               |
| 4  | AZ2  | AZ2               |
| 7  | AZ3  | AZ3               |
+----+------+-------------------+</codeblock></li>
        <!--  TODO missing content here -->
        <li>Check that the availability zone has been
          removed:<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-remove-host AZ2 padawan-ccp-comp0002-mgmt</codeblock><codeblock>Host padawan-ccp-comp0002-mgmt has been successfully removed from aggregate 4</codeblock><codeblock>+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li>
        <li>Get availability zone aggregate
          details<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-details AZ2</codeblock><codeblock>+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li>
        <li>Delete service ID 22 (AZ2) and check that is deleted using <codeph>nova
            service-list</codeph><codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-delete 22
stack@padawan-ccp-c0-m1-mgmt:~$ nova service-list</codeblock><codeblock>+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host                      | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-conductor   | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:56.000000 | -               |
| 4  | nova-scheduler   | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 7  | nova-conductor   | padawan-ccp-c1-m3-mgmt    | internal | enabled | up    | 2015-10-12T08:47:54.000000 | -               |
| 10 | nova-conductor   | padawan-ccp-c1-m2-mgmt    | internal | enabled | up    | 2015-10-12T08:47:52.000000 | -               |
| 13 | nova-scheduler   | padawan-ccp-c1-m3-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 16 | nova-consoleauth | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:54.000000 | -               |
| 19 | nova-scheduler   | padawan-ccp-c1-m2-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 25 | nova-compute     | padawan-ccp-comp0001-mgmt | AZ1      | enabled | up    | 2015-10-12T08:47:51.000000 | -               |
| 28 | nova-compute     | padawan-ccp-comp0003-mgmt | AZ3      | enabled | up    | 2015-10-12T08:47:51.000000 | -               |
+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+</codeblock>
        </li>
      </ol>
    </section>
    <section><title>Remove the Nodes</title>
      <ol>
        <li>For example, using a cloud administrator account first disable provisioning and then run
            <codeph>nova service-list</codeph>
          <codeblock>~$ nova service-disable --reason="HNOV-240 - removed" hlm004-ccp-comp0004-mgmt nova-compute
~$ nova service-list</codeblock>
          to see the
          result<codeblock>+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at | Disabled Reason |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
...
| 40 | nova-compute     | hlm004-ccp-comp0005-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 46 | nova-compute     | hlm004-ccp-comp0002-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 49 | nova-compute     | hlm004-ccp-comp0006-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 52 | nova-compute     | hlm004-ccp-comp0003-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 55 | nova-compute     | hlm004-ccp-comp0001-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:56.000000 | -                  |
| 58 | nova-compute     | hlm004-ccp-comp0004-mgmt | nova     | disabled | up    | 2015-09-17T10:29:55.000000 | HNOV-240 - removed |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock>
        </li>
        <li> Next,
          run<codeblock>~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock> to
          see all
          tenants<codeblock>+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | ACTIVE | -          | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+</codeblock>
        </li>
        <li> Now, perform the
          migration:<codeblock>~$ nova live-migration --block-migrate 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9
~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock>
          and run nova list (above) to get the
          status:<codeblock>+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status    | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | MIGRATING | migrating  | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+</codeblock>
        </li>
        <li> Run nova list again
          <codeblock>~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock> to see
          that the running instance has been
          migrated:<codeblock>+----+------+-----------+--------+------------+-------------+----------+
| ID | Name | Tenant ID | Status | Task State | Power State | Networks |
+----+------+-----------+--------+------------+-------------+----------+
+----+------+-----------+--------+------------+-------------+----------+</codeblock>
        </li>
        <li> Log into the compute node and stop the nova service <!--<note>The specified node "ccp-0004" (which
            is the node's 'cobbler' name) should match the desired node (hlm004-ccp-comp0004-mgmt).
            However, ccp-0004 does not necessarily match hlm004-ccp-comp0004-mgmt. This means you
            could easily power down the wrong node because, for example, ccp-0004 might actually map
            to hlm004-ccp-comp0008-mgmt. So, to ensure that you are powering down the correct node,
            you need to map from the hlm004-ccp-comp0004-mgmt system name to the matching cobbler
            name. To do so, find the IP address of hlm004-ccp-comp0004-mgmt by searching in the
              <b>/etc/hosts</b> file. Then search for IP address value in the
              <b>/home/stack/helion/my_cloud/definition/data/servers.yml</b> file and choose the
            corresponding <b>id field</b> value. That will be the cobbler ID of the node you are
            looking for.</note>-->
          <note>Before proceeding, you may want to take a look at <b>info/server_info.yml</b> to see
            if the assignment of the node you have added is what you expect. It may not be, as nodes
            will not be numbered consecutively if any have previously been removed. This is to
            prevent loss of data; the config processor retains data about removed nodes and keeps
            their ID numbers from being reallocated. See the <xref
              href="../input_model.dita#input_model/persistedserverallocations">Persisted Server
              Allocations</xref> section in HPE Helion OpenStack 2.0 Input Model for information on
            how this works.</note>
          <codeblock>~$ ssh stack@hlm004-ccp-comp0004-mgmt "sudo systemctl stop nova-compute"</codeblock>
          or shut down the node. (alternatively, you may re-image the
          node):<codeblock>~$ ssh stack@hlm004-ccp-comp0004-mgmt "sudo shutdown now"</codeblock>Alternatively,
          from the deployer, run the <b>bm-power-down.yml </b>playbook <codeblock>~$ cd ~/helion/hos/ansible
    ~/helion/hos/ansible$ ansible-playbook -i hosts/localhost bm-power-down.yml -e nodelist=cpn-0004</codeblock>
          <codeblock>PLAY [localhost] **************************************************************
    GATHERING FACTS *************************************************************** 
    ok: [localhost]
    TASK: [cobbler | get-nodelist | User-specified target list] ******************* 
    ok: [localhost]
    TASK: [cobbler | get-nodelist | Check we have targets] ************************ 
    skipping: [localhost]
    TASK: [debug var=target_nodes] ************************************************ 
    ok: [localhost] => {
    "var": {
    "target_nodes": [
    "cpn-0004"
    ]
    }
    }
    TASK: [cobbler | power-down | Power the nodes down] *************************** 
    changed: [localhost] => (item=cpn-0004)
    PLAY RECAP ******************************************************************** 
    cobbler | power-down | Power the nodes down ----------------------------- 1.48s
    cobbler | get-nodelist | User-specified target list --------------------- 0.02s
    debug var=target_nodes -------------------------------------------------- 0.01s
    cobbler | get-nodelist | Check we have targets -------------------------- 0.01s
    -------------------------------------------------------------------------------
    Total: ------------------------------------------------------------------ 3.54s
    localhost : ok=4 changed=1 unreachable=0 failed=0</codeblock>
        </li>
        <li>Next, delete the nova compute node:
          <codeblock>~$ nova service-delete 58
~$ nova service-list</codeblock> And run nova
          service-list (above) to see that it s
          gone:<codeblock>+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at | Disabled Reason |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
...
| 40 | nova-compute     | hlm004-ccp-comp0005-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 46 | nova-compute     | hlm004-ccp-comp0002-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 49 | nova-compute     | hlm004-ccp-comp0006-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 52 | nova-compute     | hlm004-ccp-comp0003-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 55 | nova-compute     | hlm004-ccp-comp0001-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:56.000000 | -                  |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock>
        </li>
        <li>Then get hypervisor status:<codeblock>~$ nova hypervisor-list</codeblock> And check that
          the node has been removed from the
          list:<codeblock>+----+--------------------------+-------+---------+
| ID | Hypervisor hostname      | State | Status  |
+----+--------------------------+-------+---------+
| 1  | hlm004-ccp-comp0005-mgmt | up    | enabled |
| 7  | hlm004-ccp-comp0002-mgmt | up    | enabled |
| 10 | hlm004-ccp-comp0006-mgmt | up    | enabled |
| 13 | hlm004-ccp-comp0003-mgmt | up    | enabled |
| 16 | hlm004-ccp-comp0001-mgmt | up    | enabled |
+----+--------------------------+-------+---------+</codeblock>
        </li>
        <li>Then, on the lifecycle manager, remove the node from <b>servers.yml </b><note>Make sure
            you are removing the correct node from <b>servers.yml</b> by ensuring you remove the
            stanza that contains the IP address that matches the node to be removed.</note> Edit
            <b>servers.yml </b>to remove the entry for removed node.
          <codeblock>cd ~/helion/my_cloud/definition/data
git checkout site</codeblock>
        </li>
        <li>Then, commit the change, and rerun the config processor:
          <codeblock>git commit -a -m "Removed node &lt;name>"
cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock>
        </li>
        <li>There is no need to run the site.yml playbook. However you should remove the node from
          cobbler, as shown
          here:<codeblock>sudo cobbler system remove --name=&lt;node>
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock>
        </li>
      </ol>
    </section>

    <section id="monitoring"><title>Removing the Node from Monitoring</title>
      <p>Once you have removed the Compute nodes, the alarms against them will trigger so there are
        additional steps to take to resolve this issue.</p>
      <p>You will want to SSH to each of the Monasca API servers and edit the
          <codeph>/etc/monasca/agent/conf.d/host_alive.yaml</codeph> file to remove references to
        the Compute node you removed. This will require <codeph>sudo</codeph> access. The entries
        will look similar to the one below:</p>
      <codeblock>
- alive_test: ping
  built_by: HostAlive
  host_name: helion-cp1-comp0001-mgmt
  name: helion-cp1-comp0001-mgmt ping</codeblock>
      <p>Once you have removed the references on each of your Monasca API servers you then need to
        restart the Monasca Agent on each of those servers with this command:</p>
      <codeblock>sudo service monasca-agent restart</codeblock>
      <p>With the Compute node references removed and the Monasca Agent restarted, you can then
        delete the corresponding alarm to finish this process. To do so we recommend using the
        Monasca CLI which should be installed on each of your Monasca API servers by default:</p>
      <codeblock>monasca alarm-list --metric-name host_alive_status --metric-dimensions hostname=&#60;compute node deleted></codeblock>
      <p>For example, if your Compute node looked like the example above then you would use this
        command to get the alarm ID:</p>
      <codeblock>monasca alarm-list --metric-name host_alive_status --metric-dimensions hostname=helion-cp1-comp0001-mgmt</codeblock>
      <p>You can then delete the alarm with this command:</p>
      <codeblock>monasca alarm-delete &#60;alarm ID></codeblock>
    </section>
  </body>
</topic>
